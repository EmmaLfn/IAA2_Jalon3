# -*- coding: utf-8 -*-
"""Jalon1_WarmUp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yKaCxNvpr2PkCG0KyJKtQdEQbg1EHmq_
"""

import pandas as pd
import numpy as np
import os
from sklearn.feature_extraction.text import TfidfVectorizer


from wordcloud import WordCloud
import pickle
import nltk
nltk.download('wordnet')
nltk.download('omw-1.4')
from nltk.tokenize import RegexpTokenizer
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
import contractions
nltk.download('averaged_perceptron_tagger')


import string
tokenizer = RegexpTokenizer('\w+|\$[\d\.]+|\S+')

def tokenization(text): 
  return tokenizer.tokenize(contractions.fix(text.lower().translate(str.maketrans('', '', string.punctuation))))



nltk.download('stopwords')
stop_words=nltk.corpus.stopwords.words('english')

#Répertoire des stop_words negatifs
stop_words_negatifs = ['no','never', 'not', 'nor', "don't", "aren't", 'didn', "didn't", 'doesn', "doesn't",'aren', 'couldn', "couldn't", 'hadn', "hadn't", 'hasn',"hasn't", 'haven', "haven't", 'isn', "isn't", 'mightn', "mightn't", 'mustn', "mustn't", 'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't", 'wasn', "wasn't", 'weren', "weren't", 'won', "won't", 'wouldn', "wouldn't"]

#Les stop_words négatifs sont enlevés dans un premier temps
stop_words_sans_neg = [x for x in stop_words if x not in stop_words_negatifs]

def enlever_stop_words_sans_neg(tokens):
  return [x for x in tokens if x not in stop_words_sans_neg]


#Ici on associe les stop words négatifs répertoriés dans stop_words_negatifs aux mots qui leur succèdent 
#pour garder des expressions négatives plus exploitables

def associations(tokens):
  index = []
  for i in range(len(tokens)):
    if tokens[i] in stop_words_negatifs:
      index.append(i)
  for x in index :
    if x < len(index) :
      tokens[x+1] = tokens[x] +" "+ tokens[x+1]
    else :
      tokens[x] = tokens[x]
  return tokens

  

#Les stop_words négatifs étant maintenant regroupés avec le mot suivant, on enlève les mots négatifs seuls

def enlever_stop_words_neg(tokens):
  return [x for x in tokens if x not in stop_words_negatifs]



def pos_tagging(tokens):
  return nltk.pos_tag(tokens)


lem = WordNetLemmatizer()

def lemmatisation(tokens_tag):
  liste = list()
  for word, tag in tokens_tag:
    if tag.startswith('J'):
      liste.append(lem.lemmatize(word, 'a'))
    elif tag.startswith('V'):
      liste.append(lem.lemmatize(word, 'v'))
    elif tag.startswith('N'):
      liste.append(lem.lemmatize(word, 'n'))
    elif tag.startswith('R'):
      liste.append(lem.lemmatize(word, 'r'))
    else : 
      liste.append(lem.lemmatize(word))
  return " ".join(liste)


index_topics = ['Installation', 'Manager', 'Bar', 'Hamburger', 'Sushi', 'Sandwich','Attente', 'Problème de commande', 'Serveurs', 'Pizza', 'Prix', 'Evolution', 'Coffee', 'Plat mexicain', 'Poulet curry'  ]

from textblob import TextBlob


def prediction(review):
  blob = TextBlob(review)
  sentiment = blob.sentiment
  if sentiment.polarity > 0:
    print("La review est positive")
  else : 
    #Traitement de la review 
    tokens = tokenization(review)
    tokens_stop_word = enlever_stop_words_sans_neg(tokens)
    associations_tokens = associations(tokens_stop_word)
    tokens_association_neg = enlever_stop_words_neg(associations_tokens)
    pos_tagging_tokens = pos_tagging(tokens_association_neg)
    lem_tokens = lemmatisation(pos_tagging_tokens)

    #Vectorisation
    file = open("./tfidf.vec",'rb')
    vect = pickle.load(file)
    x = vect.transform([lem_tokens])

    #Prédiction dans le modèle
    file = open("./nmf.model15",'rb')
    model = pickle.load(file)
    results = model.transform(x.toarray())
    result = np.argmax(results[0])
    topic = index_topics[result]
    return results, topic


import streamlit as st
st.title('Analyse de commentaire')

txt = st.text_area("",placeholder="Entrez un commentaire")

result = st.button("Rechercher le sujet")

if result : 
	results, topic = prediction(txt)
	st.write('Sujet :', topic)
	
	df = pd.DataFrame(
    		results)

	st.table(df)
